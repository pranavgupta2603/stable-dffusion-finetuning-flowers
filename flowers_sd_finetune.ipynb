{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v92yeE-uOxsz",
        "outputId": "1d8750fa-2374-463d-9653-d41d8bdfacdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.9/dist-packages (0.15.0.dev0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.26.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.9/dist-packages (0.16.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.9/dist-packages (2.10.1)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.9/dist-packages (6.1.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from diffusers) (2022.6.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from diffusers) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from diffusers) (2.25.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from diffusers) (8.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.9/dist-packages (from diffusers) (6.0.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from diffusers) (0.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from diffusers) (3.9.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from accelerate) (1.13.1+cu116)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from accelerate) (5.4.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.3.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.9/dist-packages (from ftfy) (0.2.6)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (3.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.10.0->diffusers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->diffusers) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->diffusers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->diffusers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->diffusers) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata->diffusers) (3.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade diffusers transformers accelerate datasets ftfy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/huggingface/diffusers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bPaAoIaYzfU",
        "outputId": "5ad02f82-204b-428e-884b-13777a0025f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'diffusers' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/justinpinkney/stable-diffusion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPqSeH6WNhI-",
        "outputId": "64fa6909-ab3e-4d7c-d909-24ae0271faaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'stable-diffusion' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/huggingface/diffusers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJ4za0BLZIbB",
        "outputId": "0f47e6ae-9a15-4e3f-a8ad-0d9cd1ba6e37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/huggingface/diffusers\n",
            "  Cloning https://github.com/huggingface/diffusers to /tmp/pip-req-build-xe24g76i\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/diffusers /tmp/pip-req-build-xe24g76i\n",
            "  Resolved https://github.com/huggingface/diffusers to commit 6a7a5467cab6df8bb24b20a7ad3f2223c1a2e8de\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.9/dist-packages (from diffusers==0.15.0.dev0) (6.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from diffusers==0.15.0.dev0) (2.25.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from diffusers==0.15.0.dev0) (1.22.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from diffusers==0.15.0.dev0) (3.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from diffusers==0.15.0.dev0) (0.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from diffusers==0.15.0.dev0) (8.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from diffusers==0.15.0.dev0) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.10.0->diffusers==0.15.0.dev0) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.10.0->diffusers==0.15.0.dev0) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.10.0->diffusers==0.15.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.10.0->diffusers==0.15.0.dev0) (23.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata->diffusers==0.15.0.dev0) (3.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->diffusers==0.15.0.dev0) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->diffusers==0.15.0.dev0) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->diffusers==0.15.0.dev0) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->diffusers==0.15.0.dev0) (4.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wg0ajn98PVFX",
        "outputId": "e8b7587e-4084-4d3a-c5a4-54352a0a3591"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "    \n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I24e4zV3PYEv",
        "outputId": "9070ee30-13eb-4967-da1d-89d735b9da3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-09 16:19:43.238689: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-09 16:19:44.160854: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-09 16:19:44.160973: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-09 16:19:44.160994: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2023-03-09 16:19:49.392251: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-09 16:19:49.392372: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-09 16:19:49.392397: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "/usr/local/lib/python3.9/dist-packages/accelerate/accelerator.py:231: FutureWarning: `logging_dir` is deprecated and will be removed in version 0.18.0 of ðŸ¤— Accelerate. Use `project_dir` instead.\n",
            "  warnings.warn(\n",
            "03/09/2023 16:19:54 - INFO - __main__ - Distributed environment: NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "Mixed precision type: fp16\n",
            "\n",
            "Downloading (â€¦)cheduler_config.json: 100% 313/313 [00:00<00:00, 43.0kB/s]\n",
            "{'thresholding', 'sample_max_value', 'prediction_type', 'clip_sample_range', 'dynamic_thresholding_ratio', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "Downloading (â€¦)tokenizer/vocab.json: 100% 1.06M/1.06M [00:01<00:00, 953kB/s]\n",
            "Downloading (â€¦)tokenizer/merges.txt: 100% 525k/525k [00:00<00:00, 591kB/s]\n",
            "Downloading (â€¦)cial_tokens_map.json: 100% 472/472 [00:00<00:00, 171kB/s]\n",
            "Downloading (â€¦)okenizer_config.json: 100% 806/806 [00:00<00:00, 320kB/s]\n",
            "Downloading (â€¦)_encoder/config.json: 100% 592/592 [00:00<00:00, 90.1kB/s]\n",
            "Downloading pytorch_model.bin: 100% 492M/492M [00:06<00:00, 77.7MB/s]\n",
            "Downloading (â€¦)on_pytorch_model.bin: 100% 335M/335M [00:01<00:00, 285MB/s]\n",
            "Downloading (â€¦)main/vae/config.json: 100% 551/551 [00:00<00:00, 187kB/s]\n",
            "{'norm_num_groups'} was not found in config. Values will be initialized to default values.\n",
            "Downloading (â€¦)on_pytorch_model.bin: 100% 3.44G/3.44G [00:45<00:00, 75.8MB/s]\n",
            "Downloading (â€¦)ain/unet/config.json: 100% 743/743 [00:00<00:00, 123kB/s]\n",
            "{'timestep_post_act', 'use_linear_projection', 'conv_out_kernel', 'class_embed_type', 'time_embedding_type', 'resnet_time_scale_shift', 'upcast_attention', 'mid_block_type', 'only_cross_attention', 'projection_class_embeddings_input_dim', 'dual_cross_attention', 'conv_in_kernel', 'num_class_embeds', 'time_cond_proj_dim'} was not found in config. Values will be initialized to default values.\n",
            "{'timestep_post_act', 'use_linear_projection', 'conv_out_kernel', 'class_embed_type', 'time_embedding_type', 'resnet_time_scale_shift', 'upcast_attention', 'mid_block_type', 'only_cross_attention', 'projection_class_embeddings_input_dim', 'dual_cross_attention', 'conv_in_kernel', 'num_class_embeds', 'time_cond_proj_dim'} was not found in config. Values will be initialized to default values.\n",
            "Downloading readme: 100% 443/443 [00:00<00:00, 120kB/s]\n",
            "Downloading and preparing dataset None/None to /root/.cache/huggingface/datasets/pranked03___parquet/pranked03--flowers-blip-captions-b982889d357441ec/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n",
            "Downloading data files:   0% 0/1 [00:00<?, ?it/s]\n",
            "Downloading data:   0% 0.00/277M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   0% 17.4k/277M [00:00<54:34, 84.6kB/s]\u001b[A\n",
            "Downloading data:   0% 52.2k/277M [00:00<34:41, 133kB/s] \u001b[A\n",
            "Downloading data:   0% 138k/277M [00:00<17:41, 261kB/s] \u001b[A\n",
            "Downloading data:   0% 296k/277M [00:00<10:07, 456kB/s]\u001b[A\n",
            "Downloading data:   0% 609k/277M [00:01<05:32, 831kB/s]\u001b[A\n",
            "Downloading data:   0% 1.25M/277M [00:01<02:52, 1.60MB/s]\u001b[A\n",
            "Downloading data:   1% 2.53M/277M [00:01<01:29, 3.07MB/s]\u001b[A\n",
            "Downloading data:   2% 5.09M/277M [00:01<00:45, 5.98MB/s]\u001b[A\n",
            "Downloading data:   3% 9.12M/277M [00:01<00:26, 10.1MB/s]\u001b[A\n",
            "Downloading data:   5% 13.1M/277M [00:02<00:20, 12.8MB/s]\u001b[A\n",
            "Downloading data:   6% 17.2M/277M [00:02<00:17, 14.7MB/s]\u001b[A\n",
            "Downloading data:   8% 21.2M/277M [00:02<00:16, 15.9MB/s]\u001b[A\n",
            "Downloading data:   9% 25.2M/277M [00:02<00:14, 16.8MB/s]\u001b[A\n",
            "Downloading data:  11% 29.2M/277M [00:02<00:14, 17.4MB/s]\u001b[A\n",
            "Downloading data:  12% 33.3M/277M [00:03<00:13, 18.0MB/s]\u001b[A\n",
            "Downloading data:  13% 37.3M/277M [00:03<00:13, 18.1MB/s]\u001b[A\n",
            "Downloading data:  15% 41.3M/277M [00:03<00:12, 18.3MB/s]\u001b[A\n",
            "Downloading data:  16% 45.3M/277M [00:03<00:12, 18.5MB/s]\u001b[A\n",
            "Downloading data:  18% 49.4M/277M [00:04<00:12, 18.7MB/s]\u001b[A\n",
            "Downloading data:  19% 53.4M/277M [00:04<00:11, 18.7MB/s]\u001b[A\n",
            "Downloading data:  21% 57.4M/277M [00:04<00:11, 18.8MB/s]\u001b[A\n",
            "Downloading data:  22% 61.5M/277M [00:04<00:11, 18.8MB/s]\u001b[A\n",
            "Downloading data:  24% 65.5M/277M [00:04<00:11, 18.8MB/s]\u001b[A\n",
            "Downloading data:  25% 69.5M/277M [00:05<00:11, 18.8MB/s]\u001b[A\n",
            "Downloading data:  27% 73.5M/277M [00:05<00:10, 18.8MB/s]\u001b[A\n",
            "Downloading data:  28% 77.5M/277M [00:05<00:10, 18.8MB/s]\u001b[A\n",
            "Downloading data:  29% 81.4M/277M [00:05<00:10, 18.8MB/s]\u001b[A\n",
            "Downloading data:  31% 85.5M/277M [00:05<00:10, 18.9MB/s]\u001b[A\n",
            "Downloading data:  32% 89.5M/277M [00:06<00:09, 18.9MB/s]\u001b[A\n",
            "Downloading data:  34% 93.6M/277M [00:06<00:09, 18.9MB/s]\u001b[A\n",
            "Downloading data:  35% 97.6M/277M [00:06<00:09, 18.9MB/s]\u001b[A\n",
            "Downloading data:  37% 102M/277M [00:06<00:09, 18.9MB/s] \u001b[A\n",
            "Downloading data:  38% 105M/277M [00:06<00:09, 17.9MB/s]\u001b[A\n",
            "Downloading data:  39% 109M/277M [00:07<00:09, 18.1MB/s]\u001b[A\n",
            "Downloading data:  41% 113M/277M [00:07<00:08, 18.4MB/s]\u001b[A\n",
            "Downloading data:  42% 117M/277M [00:07<00:08, 18.6MB/s]\u001b[A\n",
            "Downloading data:  44% 121M/277M [00:07<00:08, 18.6MB/s]\u001b[A\n",
            "Downloading data:  45% 125M/277M [00:08<00:08, 18.7MB/s]\u001b[A\n",
            "Downloading data:  47% 129M/277M [00:08<00:07, 18.7MB/s]\u001b[A\n",
            "Downloading data:  48% 133M/277M [00:08<00:07, 18.7MB/s]\u001b[A\n",
            "Downloading data:  49% 137M/277M [00:08<00:07, 18.8MB/s]\u001b[A\n",
            "Downloading data:  51% 141M/277M [00:08<00:07, 18.8MB/s]\u001b[A\n",
            "Downloading data:  52% 145M/277M [00:09<00:07, 18.6MB/s]\u001b[A\n",
            "Downloading data:  54% 149M/277M [00:09<00:06, 18.7MB/s]\u001b[A\n",
            "Downloading data:  55% 153M/277M [00:09<00:06, 18.7MB/s]\u001b[A\n",
            "Downloading data:  57% 157M/277M [00:09<00:06, 18.8MB/s]\u001b[A\n",
            "Downloading data:  58% 161M/277M [00:09<00:06, 18.8MB/s]\u001b[A\n",
            "Downloading data:  60% 165M/277M [00:10<00:05, 18.9MB/s]\u001b[A\n",
            "Downloading data:  61% 169M/277M [00:10<00:05, 18.8MB/s]\u001b[A\n",
            "Downloading data:  63% 173M/277M [00:10<00:05, 18.9MB/s]\u001b[A\n",
            "Downloading data:  64% 177M/277M [00:10<00:05, 18.8MB/s]\u001b[A\n",
            "Downloading data:  65% 181M/277M [00:11<00:05, 18.8MB/s]\u001b[A\n",
            "Downloading data:  67% 185M/277M [00:11<00:04, 18.9MB/s]\u001b[A\n",
            "Downloading data:  68% 189M/277M [00:11<00:04, 18.9MB/s]\u001b[A\n",
            "Downloading data:  70% 193M/277M [00:11<00:04, 19.0MB/s]\u001b[A\n",
            "Downloading data:  71% 198M/277M [00:11<00:04, 19.0MB/s]\u001b[A\n",
            "Downloading data:  73% 202M/277M [00:12<00:03, 19.1MB/s]\u001b[A\n",
            "Downloading data:  74% 206M/277M [00:12<00:03, 19.0MB/s]\u001b[A\n",
            "Downloading data:  76% 210M/277M [00:12<00:03, 19.0MB/s]\u001b[A\n",
            "Downloading data:  77% 214M/277M [00:12<00:03, 18.9MB/s]\u001b[A\n",
            "Downloading data:  79% 218M/277M [00:12<00:03, 19.0MB/s]\u001b[A\n",
            "Downloading data:  80% 222M/277M [00:13<00:02, 18.9MB/s]\u001b[A\n",
            "Downloading data:  81% 226M/277M [00:13<00:02, 18.9MB/s]\u001b[A\n",
            "Downloading data:  83% 230M/277M [00:13<00:02, 18.7MB/s]\u001b[A\n",
            "Downloading data:  84% 233M/277M [00:13<00:02, 17.3MB/s]\u001b[A\n",
            "Downloading data:  85% 237M/277M [00:14<00:02, 17.8MB/s]\u001b[A\n",
            "Downloading data:  87% 241M/277M [00:14<00:02, 18.1MB/s]\u001b[A\n",
            "Downloading data:  88% 245M/277M [00:14<00:01, 18.4MB/s]\u001b[A\n",
            "Downloading data:  89% 248M/277M [00:14<00:01, 17.4MB/s]\u001b[A\n",
            "Downloading data:  91% 252M/277M [00:14<00:01, 17.8MB/s]\u001b[A\n",
            "Downloading data:  92% 256M/277M [00:15<00:01, 18.2MB/s]\u001b[A\n",
            "Downloading data:  94% 260M/277M [00:15<00:00, 18.3MB/s]\u001b[A\n",
            "Downloading data:  95% 264M/277M [00:15<00:00, 18.5MB/s]\u001b[A\n",
            "Downloading data:  97% 268M/277M [00:15<00:00, 18.7MB/s]\u001b[A\n",
            "Downloading data:  98% 272M/277M [00:15<00:00, 18.8MB/s]\u001b[A\n",
            "Downloading data: 100% 277M/277M [00:16<00:00, 17.1MB/s]\n",
            "Downloading data files: 100% 1/1 [00:19<00:00, 19.44s/it]\n",
            "Extracting data files: 100% 1/1 [00:00<00:00, 981.81it/s]\n",
            "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/pranked03___parquet/pranked03--flowers-blip-captions-b982889d357441ec/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n",
            "100% 1/1 [00:00<00:00, 151.80it/s]\n",
            "03/09/2023 16:22:12 - INFO - __main__ - ***** Running training *****\n",
            "03/09/2023 16:22:12 - INFO - __main__ -   Num examples = 6552\n",
            "03/09/2023 16:22:12 - INFO - __main__ -   Num Epochs = 3\n",
            "03/09/2023 16:22:12 - INFO - __main__ -   Instantaneous batch size per device = 8\n",
            "03/09/2023 16:22:12 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "03/09/2023 16:22:12 - INFO - __main__ -   Gradient Accumulation steps = 2\n",
            "03/09/2023 16:22:12 - INFO - __main__ -   Total optimization steps = 1000\n",
            "Steps:   0% 0/1000 [00:09<?, ?it/s, lr=1e-5, step_loss=0.335]Traceback (most recent call last):\n",
            "  File \"/content/diffusers/examples/text_to_image/train_text_to_image.py\", line 788, in <module>\n",
            "    main()\n",
            "  File \"/content/diffusers/examples/text_to_image/train_text_to_image.py\", line 740, in main\n",
            "    optimizer.step()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/accelerate/optimizer.py\", line 134, in step\n",
            "    self.scaler.step(self.optimizer, closure)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/cuda/amp/grad_scaler.py\", line 341, in step\n",
            "    retval = self._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/cuda/amp/grad_scaler.py\", line 288, in _maybe_opt_step\n",
            "    retval = optimizer.step(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py\", line 68, in wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/optim/optimizer.py\", line 140, in wrapper\n",
            "    out = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/optim/adamw.py\", line 147, in step\n",
            "    state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 14.75 GiB total capacity; 13.22 GiB already allocated; 46.81 MiB free; 13.39 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "Steps:   0% 0/1000 [00:09<?, ?it/s, lr=1e-5, step_loss=0.335]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/accelerate/commands/accelerate_cli.py\", line 45, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/accelerate/commands/launch.py\", line 1097, in launch_command\n",
            "    simple_launcher(args)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/accelerate/commands/launch.py\", line 552, in simple_launcher\n",
            "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', 'diffusers/examples/text_to_image/train_text_to_image.py', '--pretrained_model_name_or_path=CompVis/stable-diffusion-v1-4', '--dataset_name=pranked03/flowers-blip-captions', '--use_ema', '--resolution=128', '--center_crop', '--random_flip', '--train_batch_size=8', '--gradient_accumulation_steps=2', '--gradient_checkpointing', '--mixed_precision=fp16', '--max_train_steps=1000', '--learning_rate=1e-05', '--max_grad_norm=1', '--lr_scheduler=constant', '--lr_warmup_steps=0', '--output_dir=sd-flowers-model']' returned non-zero exit status 1.\n"
          ]
        }
      ],
      "source": [
        "!accelerate launch diffusers/examples/text_to_image/train_text_to_image.py \\\n",
        "  --pretrained_model_name_or_path=\"CompVis/stable-diffusion-v1-4\" \\\n",
        "  --dataset_name=\"pranked03/flowers-blip-captions\" \\\n",
        "  --use_ema \\\n",
        "  --resolution=128 --center_crop --random_flip \\\n",
        "  --train_batch_size=8 \\\n",
        "  --gradient_accumulation_steps=2 \\\n",
        "  --gradient_checkpointing \\\n",
        "  --mixed_precision=\"fp16\" \\\n",
        "  --max_train_steps=1000 \\\n",
        "  --learning_rate=1e-05 \\\n",
        "  --max_grad_norm=1 \\\n",
        "  --lr_scheduler=\"constant\" --lr_warmup_steps=0 \\\n",
        "  --output_dir=\"sd-flowers-model\" "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
